{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "# prefer to use this package for NMF because it is faster\n",
    "from nonnegfac.nmf import NMF_ANLS_BLOCKPIVOT\n",
    "# however, sklearn implementation of NMF could be used as well\n",
    "# from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import normalize\n",
    "import h5py\n",
    "from scipy import sparse\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def download_and_unpack_zip_file(url, path, targetdir):\n",
    "    wget.download(url, path)\n",
    "    shutil.unpack_archive(path, targetdir)\n",
    "\n",
    "def prepare_directories():\n",
    "    directories_to_create = ['downloaded', 'raw', 'dataframes', 'tmp']\n",
    "    for directory in directories_to_create:\n",
    "        dirname = '/'.join(['../data', directory])\n",
    "        Path(dirname).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def download_datasets():\n",
    "    lfm1b_dataset_url = 'http://drive.jku.at/ssf/s/readFile/share/1056/266403063659030189/publicLink/LFM-1b.zip'\n",
    "    lfm1b_ugp_dataset_url = 'http://www.cp.jku.at/datasets/LFM-1b/LFM-1b_UGP.zip'\n",
    "    lfm1b_social_dataset_url = 'https://zenodo.org/record/5585638/files/LFM-1b_social.zip?download=1'\n",
    "\n",
    "    targetdir = '../data/raw'\n",
    "    print('Downloading and unpacking LFM-1b dataset (~8GB)...')\n",
    "    download_and_unpack_zip_file(lfm1b_dataset_url, '../data/downloaded/LFM-1b.zip', targetdir)\n",
    "    print('Finished.')\n",
    "\n",
    "    print('Downloading and unpacking LFM-1b_UGP dataset (~166MB)...')\n",
    "    download_and_unpack_zip_file(lfm1b_ugp_dataset_url, '../data/downloaded/LFM-1b_UGP.zip', targetdir)\n",
    "    print('Finished.')\n",
    "\n",
    "    print('Downloading and unpacking LFM-1b_social dataset (~2MB)...')\n",
    "    download_and_unpack_zip_file(lfm1b_social_dataset_url, '../data/downloaded/LFM-1b_social.zip', targetdir)\n",
    "    print('Finished.')\n",
    "\n",
    "\n",
    "def create_lfm1b_users_df(lfm1b_users_filepath):\n",
    "    lfm1b_users_df = pd.read_csv(lfm1b_users_filepath, sep='\\t')\n",
    "    lfm1b_users_df.to_csv('../data/raw/LFM-1b_social/LFM-1b_users.txt', sep = '\\t', index=False)\n",
    "    return lfm1b_users_df\n",
    "\n",
    "\n",
    "def create_users_df(edgelist_df,\n",
    "                    lfm1b_user_info_filepath,\n",
    "                    lfm1b_user_additional_info_filepath,\n",
    "                    lfm1b_user_genres_allmusic_filepath,\n",
    "                    replace_missing_values_with_mean=False):\n",
    "    users_list = list(edgelist_df.user1_id.unique())\n",
    "    users_list.extend(list(edgelist_df.user2_id.unique()))\n",
    "    users_list = list(set(users_list))\n",
    "    users_df = pd.DataFrame(users_list).rename(columns={0:'user_id'})\n",
    "    lfm1b_user_info_df = pd.read_csv(lfm1b_user_info_filepath, sep='\\t').drop(columns=['registered_unixtime'])\n",
    "    users_df = users_df.merge(lfm1b_user_info_df, how='left', on='user_id')\n",
    "    users_df['age_group'] = users_df['age'].apply(get_age_group)\n",
    "    users_df.loc[users_df['gender'].isnull(), 'gender'] = 'n'\n",
    "    users_df.loc[users_df['country'].isnull(), 'country'] = 'N/A'\n",
    "    users_df.loc[users_df['playcount'] == 0, 'playcount'] = 1\n",
    "    users_df['playcount_lognorm'] = np.log(users_df['playcount'])\n",
    "    users_df = users_df.drop(columns=['playcount'])\n",
    "    lfm1b_user_additional_info_df = pd.read_csv(lfm1b_user_additional_info_filepath, sep='\\t').rename(columns={'user-id':'user_id'}).replace('?', None).astype({'novelty_artist_avg_month': 'float64',\n",
    "                            'novelty_artist_avg_year': 'float64',\n",
    "                            'mainstreaminess_avg_6months':'float64',\n",
    "                            'relative_le_per_weekday1':'float64',\n",
    "                            'relative_le_per_weekday2':'float64',\n",
    "                            'relative_le_per_weekday3':'float64',\n",
    "                            'relative_le_per_weekday4':'float64',\n",
    "                            'relative_le_per_weekday5':'float64',\n",
    "                            'relative_le_per_weekday6':'float64',\n",
    "                            'relative_le_per_weekday7':'float64',\n",
    "                            'relative_le_per_hour0':'float64',\n",
    "                            'relative_le_per_hour1':'float64',\n",
    "                            'relative_le_per_hour2':'float64',\n",
    "                            'relative_le_per_hour3':'float64',\n",
    "                            'relative_le_per_hour4':'float64',\n",
    "                            'relative_le_per_hour5':'float64',\n",
    "                            'relative_le_per_hour6':'float64',\n",
    "                            'relative_le_per_hour7':'float64',\n",
    "                            'relative_le_per_hour8':'float64',\n",
    "                            'relative_le_per_hour9':'float64',\n",
    "                            'relative_le_per_hour10':'float64',\n",
    "                            'relative_le_per_hour11':'float64',\n",
    "                            'relative_le_per_hour12':'float64',\n",
    "                            'relative_le_per_hour13':'float64',\n",
    "                            'relative_le_per_hour14':'float64',\n",
    "                            'relative_le_per_hour15':'float64',\n",
    "                            'relative_le_per_hour16':'float64',\n",
    "                            'relative_le_per_hour17':'float64',\n",
    "                            'relative_le_per_hour18':'float64',\n",
    "                            'relative_le_per_hour19':'float64',\n",
    "                            'relative_le_per_hour20':'float64',\n",
    "                            'relative_le_per_hour21':'float64',\n",
    "                            'relative_le_per_hour22':'float64',\n",
    "                            'relative_le_per_hour23':'float64'})\n",
    "    users_df = users_df.merge(lfm1b_user_additional_info_df, how='left', on='user_id')\n",
    "    users_df.loc[users_df['cnt_listeningevents'] == 0, 'cnt_listeningevents'] = 1\n",
    "    users_df['cnt_listeningevents_lognorm'] = np.log(users_df['cnt_listeningevents'])\n",
    "    users_df = users_df.drop(columns=['cnt_listeningevents'])\n",
    "    users_df.loc[users_df['cnt_distinct_tracks'] == 0, 'cnt_distinct_tracks'] = 1\n",
    "    users_df['cnt_distinct_tracks_lognorm'] = np.log(users_df['cnt_distinct_tracks'])\n",
    "    users_df = users_df.drop(columns=['cnt_distinct_tracks'])\n",
    "    users_df.loc[users_df['cnt_distinct_artists'] == 0, 'cnt_distinct_artists'] = 1\n",
    "    users_df['cnt_distinct_artists_lognorm'] = np.log(users_df['cnt_distinct_artists'])\n",
    "    users_df = users_df.drop(columns=['cnt_distinct_artists'])\n",
    "    users_df.loc[users_df['cnt_listeningevents_per_week'] == 0, 'cnt_listeningevents_per_week'] = 1\n",
    "    users_df['cnt_listeningevents_per_week_lognorm'] = np.log(users_df['cnt_listeningevents_per_week'])\n",
    "    users_df = users_df.drop(columns=['cnt_listeningevents_per_week'])\n",
    "    dummies = pd.get_dummies(users_df.country, prefix='country')\n",
    "    users_df =  pd.concat([users_df, dummies.set_index(users_df.index)], axis=1)\n",
    "    dummies = pd.get_dummies(users_df.gender, prefix='gender')\n",
    "    users_df = pd.concat([users_df, dummies.set_index(users_df.index)], axis=1)\n",
    "    dummies = pd.get_dummies(users_df.age_group, prefix='age_group')\n",
    "    users_df = pd.concat([users_df, dummies.set_index(users_df.index)], axis=1)\n",
    "\n",
    "    # Loading allmusic genres and calculating diversities\n",
    "    lfm1b_user_genres_allmusic_df = pd.read_csv(lfm1b_user_genres_allmusic_filepath, sep='\\t')\n",
    "    if os.path.isfile('../data/tmp/allmusic_diversity_df.csv'):\n",
    "        allmusic_diversity_df = pd.read_csv('../data/tmp/allmusic_diversity_df.csv', index_col=0)\n",
    "    else:\n",
    "        allmusic_diversity_df = create_allmusic_diversity_df(lfm1b_user_genres_allmusic_df, users_df)\n",
    "    users_df = users_df.merge(allmusic_diversity_df, how='left', on='user_id')\n",
    "\n",
    "    lfm1b_user_genres_allmusic_df_user_ids = pd.DataFrame(lfm1b_user_genres_allmusic_df.user_id)\n",
    "    lfm1b_user_genres_allmusic_df_genres = pd.DataFrame(lfm1b_user_genres_allmusic_df.drop(['user_id'], axis=1))\n",
    "    lfm1b_user_genres_allmusic_df_genres = lfm1b_user_genres_allmusic_df_genres.div(lfm1b_user_genres_allmusic_df_genres.max(axis=1), axis=0).add_prefix('allmusic_')\n",
    "    lfm1b_user_genres_allmusic_df = pd.concat([lfm1b_user_genres_allmusic_df_user_ids, lfm1b_user_genres_allmusic_df_genres.set_index(lfm1b_user_genres_allmusic_df_user_ids.index)], axis=1)\n",
    "    users_df = users_df.merge(lfm1b_user_genres_allmusic_df, how='left', on='user_id')\n",
    "\n",
    "    # Loading freebase genres and calculating diversities\n",
    "    lfm1b_user_genres_freebase_df = pd.read_csv(lfm1b_user_genres_freebase_filepath, sep='\\t')\n",
    "    if os.path.isfile('../data/tmp/freebase_diversity_df.csv'):\n",
    "        freebase_diversity_df = pd.read_csv('../data/tmp/freebase_diversity_df.csv', index_col=0)\n",
    "    else:\n",
    "        freebase_diversity_df = create_freebase_diversity_df(lfm1b_user_genres_freebase_df, users_df)\n",
    "    users_df = users_df.merge(freebase_diversity_df, how='left', on='user_id')\n",
    "\n",
    "    # Calculating NMF latent features from freebase genres\n",
    "    if os.path.isfile('../data/tmp/freebase_genres_matrix_nmf_df.csv'):\n",
    "        freebase_genres_matrix_nmf_df = pd.read_csv('../data/tmp/freebase_genres_matrix_nmf_df.csv', index_col=0)\n",
    "    else:\n",
    "        freebase_genres_matrix_nmf_df = create_freebase_genres_matrix_nmf_df(lfm1b_user_genres_freebase_df)\n",
    "    users_df = users_df.merge(freebase_genres_matrix_nmf_df, how='left', on='user_id')\n",
    "\n",
    "    # Calculating NMF latent features from the user-artist playcount matrix\n",
    "    if os.path.isfile('../data/tmp/UAM_normalized_nmf_df.csv'):\n",
    "        UAM_normalized_nmf_df = pd.read_csv('../data/tmp/UAM_normalized_nmf_df.csv', index_col=0)\n",
    "    else:\n",
    "        UAM_normalized_nmf_df = create_UAM_normalized_nmf_df(lfm1b_user_artists_LEs_filepath)\n",
    "    users_df = users_df.merge(UAM_normalized_nmf_df, how='left', on='user_id')\n",
    "\n",
    "    if replace_missing_values_with_mean == True:\n",
    "        users_df = fill_missing_values(users_df)\n",
    "\n",
    "    column_to_convert_to_user_groups = [\n",
    "        'freebase_weighted_average_diversity',\n",
    "        'freebase_genre_coverage_diversity',\n",
    "        'freebase_entropy_diversity',\n",
    "        'allmusic_weighted_average_diversity',\n",
    "        'allmusic_genre_coverage_diversity',\n",
    "        'allmusic_entropy_diversity',\n",
    "        'cnt_listeningevents_lognorm',\n",
    "        'cnt_distinct_tracks_lognorm',\n",
    "        'cnt_distinct_artists_lognorm',\n",
    "        'cnt_listeningevents_per_week_lognorm',\n",
    "        'playcount_lognorm',\n",
    "        'novelty_artist_avg_month',\n",
    "        'novelty_artist_avg_6months',\n",
    "        'novelty_artist_avg_year',\n",
    "        'mainstreaminess_avg_month',\n",
    "        'mainstreaminess_avg_6months',\n",
    "        'mainstreaminess_avg_year',\n",
    "        'mainstreaminess_global']\n",
    "    for column in column_to_convert_to_user_groups:\n",
    "        users_df = divide_column_into_user_groups_and_merge(users_df, column)\n",
    "        dummies = pd.get_dummies(users_df['user_groups_'+column], prefix='user_groups_'+column)\n",
    "        users_df = pd.concat([users_df, dummies.set_index(users_df.index)], axis=1)\n",
    "\n",
    "    outdir = '../data/dataframes/users_dfs'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.makedirs(outdir)\n",
    "    if replace_missing_values_with_mean == True:\n",
    "        print('i am here')\n",
    "        users_df.to_csv('../data/dataframes/users_dfs/users_df_no_missing_values.csv', index=False)\n",
    "    else:\n",
    "        users_df.to_csv('../data/dataframes/users_dfs/users_df.csv', index=False)\n",
    "        print('and i am here')\n",
    "\n",
    "def create_UAM_normalized_nmf_df(lfm1b_user_artists_LEs_filepath):\n",
    "    UAM, UAM_user_idx, UAM_artist_idx, user_ids, artist_ids = read_UAM(lfm1b_user_artists_LEs_filepath)\n",
    "    user_ids_df = pd.DataFrame(user_ids).rename(columns={0:'user_id'})\n",
    "    UAM = sparse.csr_matrix(UAM)\n",
    "    UAM_normalized = normalize(UAM, norm='max', axis=1)\n",
    "    UAM_normalized_nmf = create_NMF_embeddings(UAM_normalized, 20)\n",
    "    UAM_normalized_nmf_df = pd.DataFrame(UAM_normalized_nmf).add_prefix('UAM_nmf_')\n",
    "    UAM_normalized_nmf_df = pd.concat([user_ids_df, UAM_normalized_nmf_df], axis=1)\n",
    "    UAM_normalized_nmf_df.to_csv('../data/tmp/UAM_normalized_nmf_df.csv', index=False)\n",
    "    return UAM_normalized_nmf_df\n",
    "\n",
    "def create_freebase_genres_matrix_nmf_df(lfm1b_user_genres_freebase_df):\n",
    "    lfm1b_user_genres_freebase_df_user_ids = pd.DataFrame(lfm1b_user_genres_freebase_df.user_id)\n",
    "    lfm1b_user_genres_freebase_df_genres = pd.DataFrame(lfm1b_user_genres_freebase_df.drop(['user_id'], axis=1))\n",
    "    lfm1b_user_genres_freebase_df_genres = lfm1b_user_genres_freebase_df_genres.add_prefix('freebase_')\n",
    "    lfm1b_user_genres_freebase_df_genres = pd.concat([lfm1b_user_genres_freebase_df_user_ids, lfm1b_user_genres_freebase_df_genres.set_index(lfm1b_user_genres_freebase_df_user_ids.index)], axis=1)\n",
    "    freebase_genre_matrix = scipy.sparse.csr_matrix(lfm1b_user_genres_freebase_df_genres.fillna(0).values)\n",
    "    freebase_genre_matrix_normalized = normalize(freebase_genre_matrix, norm='max', axis=1)\n",
    "    freebase_genres_matrix_nmf = create_NMF_embeddings(freebase_genre_matrix_normalized, 20)\n",
    "    freebase_genres_matrix_nmf_df = pd.DataFrame(freebase_genres_matrix_nmf).add_prefix('freebase_nmf_')\n",
    "    freebase_genres_matrix_nmf_df = pd.concat([freebase_genres_matrix_nmf_df, lfm1b_user_genres_freebase_df_user_ids], axis=1)\n",
    "    freebase_genres_matrix_nmf_df.to_csv('../data/tmp/freebase_genres_matrix_nmf_df.csv', index=False)\n",
    "    return freebase_genres_matrix_nmf_df\n",
    "\n",
    "def create_freebase_diversity_df(lfm1b_user_genres_freebase_df, users_df):\n",
    "    user_ids = list(users_df.user_id.values)\n",
    "    diversity_weighted_average_list = []\n",
    "    diversity_genre_coverage_list = []\n",
    "    entropy_diversity_list = []\n",
    "    for user_id in user_ids:\n",
    "        try:\n",
    "            user_genres = lfm1b_user_genres_freebase_df[lfm1b_user_genres_freebase_df.user_id==user_id].drop(['user_id'], axis=1).values[0]\n",
    "            user_genres_normalized = user_genres/np.max(user_genres)\n",
    "            diversity_weighted_average = np.sum(user_genres_normalized)/len(user_genres_normalized)\n",
    "\n",
    "            diversity_genre_coverage = len(user_genres[user_genres > 0])/len(user_genres)\n",
    "            user_genre_counts = dict(zip(list(lfm1b_user_genres_freebase_df[lfm1b_user_genres_freebase_df.user_id==user_id].drop(['user_id'], axis=1).columns),\n",
    "                                     list(lfm1b_user_genres_freebase_df[lfm1b_user_genres_freebase_df.user_id==user_id].drop(['user_id'], axis=1).values[0])))\n",
    "            labels = []\n",
    "            for key in user_genre_counts:\n",
    "                labels.extend([key] * user_genre_counts[key])\n",
    "            entropy_diversity = entropy_label_distribution(labels)\n",
    "        except:\n",
    "            diversity_weighted_average = None\n",
    "            diversity_genre_coverage = None\n",
    "            entropy_diversity = None\n",
    "        diversity_weighted_average_list.append(diversity_weighted_average)\n",
    "        diversity_genre_coverage_list.append(diversity_genre_coverage)\n",
    "        entropy_diversity_list.append(entropy_diversity)\n",
    "    freebase_diversity_df = pd.DataFrame(\n",
    "        {'user_id': user_ids,\n",
    "         'freebase_weighted_average_diversity': diversity_weighted_average_list,\n",
    "         'freebase_genre_coverage_diversity': diversity_genre_coverage_list,\n",
    "         'freebase_entropy_diversity': entropy_diversity_list\n",
    "        })\n",
    "    freebase_diversity_df.to_csv('../data/tmp/freebase_diversity_df.csv', index=False)\n",
    "    return freebase_diversity_df\n",
    "\n",
    "def create_allmusic_diversity_df(lfm1b_user_genres_allmusic_df, users_df):\n",
    "    user_ids = list(users_df.user_id.values)\n",
    "    diversity_weighted_average_list = []\n",
    "    diversity_genre_coverage_list = []\n",
    "    entropy_diversity_list = []\n",
    "    for user_id in user_ids:\n",
    "        try:\n",
    "            user_genres = lfm1b_user_genres_allmusic_df[lfm1b_user_genres_allmusic_df.user_id==user_id].drop(['user_id'], axis=1).values[0]\n",
    "            user_genres_normalized = user_genres/np.max(user_genres)\n",
    "            diversity_weighted_average = np.sum(user_genres_normalized)/len(user_genres_normalized)\n",
    "\n",
    "            diversity_genre_coverage = len(user_genres[user_genres > 0])/len(user_genres)\n",
    "            user_genre_counts = dict(zip(list(lfm1b_user_genres_allmusic_df[lfm1b_user_genres_allmusic_df.user_id==user_id].drop(['user_id'], axis=1).columns),\n",
    "                                     list(lfm1b_user_genres_allmusic_df[lfm1b_user_genres_allmusic_df.user_id==user_id].drop(['user_id'], axis=1).values[0])))\n",
    "            labels = []\n",
    "            for key in user_genre_counts:\n",
    "                labels.extend([key] * user_genre_counts[key])\n",
    "            entropy_diversity = entropy_label_distribution(labels)\n",
    "        except:\n",
    "            diversity_weighted_average = None\n",
    "            diversity_genre_coverage = None\n",
    "            entropy_diversity = None\n",
    "        diversity_weighted_average_list.append(diversity_weighted_average)\n",
    "        diversity_genre_coverage_list.append(diversity_genre_coverage)\n",
    "        entropy_diversity_list.append(entropy_diversity)\n",
    "    allmusic_diversity_df = pd.DataFrame(\n",
    "        {'user_id': user_ids,\n",
    "         'allmusic_weighted_average_diversity': diversity_weighted_average_list,\n",
    "         'allmusic_genre_coverage_diversity': diversity_genre_coverage_list,\n",
    "         'allmusic_entropy_diversity': entropy_diversity_list\n",
    "        })\n",
    "    allmusic_diversity_df.to_csv('../data/tmp/allmusic_diversity_df.csv', index=False)\n",
    "    return allmusic_diversity_df\n",
    "\n",
    "def get_age_group(age):\n",
    "    if age == -1:\n",
    "        return '-1'\n",
    "    elif age < 5:\n",
    "        return '0-4'\n",
    "    elif age < 10:\n",
    "        return '5-9'\n",
    "    elif age < 15:\n",
    "        return '10-14'\n",
    "    elif age < 20:\n",
    "        return '15-19'\n",
    "    elif age < 25:\n",
    "        return '20-24'\n",
    "    elif age < 30:\n",
    "        return '25-29'\n",
    "    elif age < 35:\n",
    "        return '30-34'\n",
    "    elif age < 40:\n",
    "        return '35-39'\n",
    "    elif age < 45:\n",
    "        return '40-44'\n",
    "    elif age < 50:\n",
    "        return '45-49'\n",
    "    elif age < 55:\n",
    "        return '50-54'\n",
    "    elif age < 60:\n",
    "        return '55-59'\n",
    "    elif age < 65:\n",
    "        return '60-64'\n",
    "    elif age < 70:\n",
    "        return '65-69'\n",
    "    elif age < 75:\n",
    "        return '70-74'\n",
    "    elif age < 80:\n",
    "        return '75-79'\n",
    "    elif age >=80:\n",
    "        return '80+'\n",
    "\n",
    "def create_NMF_embeddings(input_matrix, dim):\n",
    "    W, _, info = NMF_ANLS_BLOCKPIVOT().run(input_matrix, dim, max_iter=100)\n",
    "    return W\n",
    "\n",
    "# Read the user-artist-matrix and corresponding artist and user indices from Matlab file\n",
    "def read_UAM(m_file):\n",
    "    mf = h5py.File(m_file, 'r')\n",
    "    user_ids = np.array(mf.get('idx_users')).astype(np.int64)\n",
    "    artist_ids = np.array(mf.get('idx_artists')).astype(np.int64)\n",
    "    # Load UAM\n",
    "    UAM = sparse.csr_matrix((mf['/LEs/'][\"data\"],\n",
    "                             mf['/LEs/'][\"ir\"],\n",
    "                             mf['/LEs/'][\"jc\"])).transpose()    #.tocoo().transpose()\n",
    "    # user and artist indices to access UAM\n",
    "    UAM_user_idx = UAM.indices #UAM.row -> for COO matrix\n",
    "    UAM_artist_idx = UAM.indptr #UAM.col -> for COO matrix\n",
    "    return UAM, UAM_user_idx, UAM_artist_idx, user_ids, artist_ids\n",
    "\n",
    "# Compute entropy of label distribution\n",
    "def entropy_label_distribution(labels):\n",
    "    n_labels = len(labels)\n",
    "    if n_labels <= 1:\n",
    "        return 0\n",
    "    value, counts = np.unique(labels, return_counts=True)\n",
    "    probs = counts / np.float32(n_labels)\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "    if n_classes <= 1:\n",
    "        return 0.0\n",
    "    # Compute entropy\n",
    "    ent = 0.0\n",
    "    for p in probs:\n",
    "        ent -= p * np.log(p)\n",
    "    return ent\n",
    "\n",
    "def divide_column_into_user_groups_and_merge(df, column_name):\n",
    "    sorted_values = np.sort(df[column_name].values)\n",
    "    third_of_a_sum = sum(sorted_values[~np.isnan(sorted_values)])/3\n",
    "    is_first_third_threshold_set = False\n",
    "    is_second_third_threshold_set = False\n",
    "    cummulative_sum = 0\n",
    "    for value in sorted_values:\n",
    "        if np.isnan(value):\n",
    "            continue\n",
    "        if cummulative_sum > third_of_a_sum and is_first_third_threshold_set==False:\n",
    "            first_third_threshold = value\n",
    "            is_first_third_threshold_set = True\n",
    "        if cummulative_sum > 2*third_of_a_sum and is_second_third_threshold_set==False:\n",
    "            second_third_threshold = value\n",
    "            is_second_third_threshold_set = True\n",
    "        cummulative_sum += value\n",
    "    user_groups = []\n",
    "    for value in df[column_name].values:\n",
    "        if np.isnan(value):\n",
    "            user_groups.append(None)\n",
    "        elif value <= first_third_threshold:\n",
    "            user_groups.append('low')\n",
    "        elif first_third_threshold < value <= second_third_threshold:\n",
    "            user_groups.append('medium')\n",
    "        elif value > second_third_threshold:\n",
    "            user_groups.append('high')\n",
    "    user_groups_df = pd.DataFrame(user_groups).rename(columns={0:'user_groups_'+column_name})\n",
    "    df = pd.concat([df, user_groups_df], axis=1)\n",
    "    return df\n",
    "\n",
    "def fill_missing_values(users_df):\n",
    "    columns_to_be_replaced_with_mean = []\n",
    "    for column in users_df.columns:\n",
    "        if users_df[column].isna().any():\n",
    "            users_df[column] = users_df[column].fillna(users_df[column].mean())\n",
    "    return users_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfm1b_user_info_filepath = '../data/raw/LFM-1b_social/LFM-1b_users.txt'\n",
    "lfm1b_user_additional_info_filepath = '../data/raw/LFM-1b/LFM-1b_users_additional.txt'\n",
    "lfm1b_user_genres_allmusic_filepath = '../data/raw/LFM-1b_UGP/LFM-1b_UGP_weightedPC_allmusic.txt'\n",
    "lfm1b_user_genres_freebase_filepath = '../data/raw/LFM-1b_UGP/LFM-1b_UGP_weightedPC_freebase.txt'\n",
    "input_edgelist_csv_filepath = '../data/raw/LFM-1b_social/LFM-1b_social_ties.txt'\n",
    "lfm1b_user_artists_LEs_filepath = '../data/raw/LFM-1b/LFM-1b_LEs.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# download and unpack datasets\n",
    "prepare_directories()\n",
    "download_datasets()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tduricic/01_Development/tools/anaconda3/envs/lastfm/lib/python3.9/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "edgelist_df = pd.read_csv('../data/raw/LFM-1b_social/LFM-1b_social_ties.txt', sep='\\t')\n",
    "users_df_without_missing_values = create_users_df(edgelist_df,\n",
    "                                                  lfm1b_user_info_filepath,\n",
    "                                                  lfm1b_user_additional_info_filepath,\n",
    "                                                  lfm1b_user_genres_allmusic_filepath,\n",
    "                                                  True)\n",
    "\n",
    "users_df_without_missing_values = create_users_df(edgelist_df,\n",
    "                                                  lfm1b_user_info_filepath,\n",
    "                                                  lfm1b_user_additional_info_filepath,\n",
    "                                                  lfm1b_user_genres_allmusic_filepath,\n",
    "                                                  False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "users_df = pd.read_csv('../data/dataframes/users_dfs/users_df.csv')\n",
    "users_df_without_missing_values = pd.read_csv('../data/dataframes/users_dfs/users_df_no_missing_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "    user_id country  age gender age_group  playcount_lognorm  \\\n0   6782979      US   23      m     20-24          11.004597   \n1   3276804     NaN   22      n     20-24          11.512335   \n2  13893641      RU   22      f     20-24          11.522579   \n3  13959183      CO   42      m     40-44          10.799739   \n4  26542097      DE   17      m     15-19           9.011646   \n\n   novelty_artist_avg_month  novelty_artist_avg_6months  \\\n0                  0.445551                    0.038635   \n1                  0.122681                    0.012701   \n2                  0.699013                    0.019885   \n3                  0.201202                    0.057450   \n4                  0.284681                    0.014349   \n\n   novelty_artist_avg_year  mainstreaminess_avg_month  ...  \\\n0                 0.590222                   0.047020  ...   \n1                 0.272727                   0.012360  ...   \n2                 0.831252                   0.015331  ...   \n3                 0.295957                   0.105565  ...   \n4                 0.417029                   0.017248  ...   \n\n   user_groups_mainstreaminess_avg_6months_low  \\\n0                                            0   \n1                                            1   \n2                                            0   \n3                                            1   \n4                                            0   \n\n   user_groups_mainstreaminess_avg_6months_medium  \\\n0                                               1   \n1                                               0   \n2                                               0   \n3                                               0   \n4                                               1   \n\n   user_groups_mainstreaminess_avg_year  \\\n0                                   low   \n1                                   low   \n2                                   low   \n3                                medium   \n4                                   low   \n\n   user_groups_mainstreaminess_avg_year_high  \\\n0                                          0   \n1                                          0   \n2                                          0   \n3                                          0   \n4                                          0   \n\n   user_groups_mainstreaminess_avg_year_low  \\\n0                                         1   \n1                                         1   \n2                                         1   \n3                                         0   \n4                                         1   \n\n   user_groups_mainstreaminess_avg_year_medium  \\\n0                                            0   \n1                                            0   \n2                                            0   \n3                                            1   \n4                                            0   \n\n   user_groups_mainstreaminess_global  \\\n0                              medium   \n1                                 low   \n2                              medium   \n3                                high   \n4                                 low   \n\n   user_groups_mainstreaminess_global_high  \\\n0                                        0   \n1                                        0   \n2                                        0   \n3                                        1   \n4                                        0   \n\n   user_groups_mainstreaminess_global_low  \\\n0                                       0   \n1                                       1   \n2                                       0   \n3                                       0   \n4                                       1   \n\n   user_groups_mainstreaminess_global_medium  \n0                                          1  \n1                                          0  \n2                                          1  \n3                                          0  \n4                                          0  \n\n[5 rows x 359 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>country</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>age_group</th>\n      <th>playcount_lognorm</th>\n      <th>novelty_artist_avg_month</th>\n      <th>novelty_artist_avg_6months</th>\n      <th>novelty_artist_avg_year</th>\n      <th>mainstreaminess_avg_month</th>\n      <th>...</th>\n      <th>user_groups_mainstreaminess_avg_6months_low</th>\n      <th>user_groups_mainstreaminess_avg_6months_medium</th>\n      <th>user_groups_mainstreaminess_avg_year</th>\n      <th>user_groups_mainstreaminess_avg_year_high</th>\n      <th>user_groups_mainstreaminess_avg_year_low</th>\n      <th>user_groups_mainstreaminess_avg_year_medium</th>\n      <th>user_groups_mainstreaminess_global</th>\n      <th>user_groups_mainstreaminess_global_high</th>\n      <th>user_groups_mainstreaminess_global_low</th>\n      <th>user_groups_mainstreaminess_global_medium</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6782979</td>\n      <td>US</td>\n      <td>23</td>\n      <td>m</td>\n      <td>20-24</td>\n      <td>11.004597</td>\n      <td>0.445551</td>\n      <td>0.038635</td>\n      <td>0.590222</td>\n      <td>0.047020</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>low</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>medium</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3276804</td>\n      <td>NaN</td>\n      <td>22</td>\n      <td>n</td>\n      <td>20-24</td>\n      <td>11.512335</td>\n      <td>0.122681</td>\n      <td>0.012701</td>\n      <td>0.272727</td>\n      <td>0.012360</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>low</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>low</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13893641</td>\n      <td>RU</td>\n      <td>22</td>\n      <td>f</td>\n      <td>20-24</td>\n      <td>11.522579</td>\n      <td>0.699013</td>\n      <td>0.019885</td>\n      <td>0.831252</td>\n      <td>0.015331</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>low</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>medium</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13959183</td>\n      <td>CO</td>\n      <td>42</td>\n      <td>m</td>\n      <td>40-44</td>\n      <td>10.799739</td>\n      <td>0.201202</td>\n      <td>0.057450</td>\n      <td>0.295957</td>\n      <td>0.105565</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>medium</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>high</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26542097</td>\n      <td>DE</td>\n      <td>17</td>\n      <td>m</td>\n      <td>15-19</td>\n      <td>9.011646</td>\n      <td>0.284681</td>\n      <td>0.014349</td>\n      <td>0.417029</td>\n      <td>0.017248</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>low</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>low</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 359 columns</p>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "    user_id country  age gender age_group  playcount_lognorm  \\\n0   6782979      US   23      m     20-24          11.004597   \n1   3276804     NaN   22      n     20-24          11.512335   \n2  13893641      RU   22      f     20-24          11.522579   \n3  13959183      CO   42      m     40-44          10.799739   \n4  26542097      DE   17      m     15-19           9.011646   \n\n   novelty_artist_avg_month  novelty_artist_avg_6months  \\\n0                  0.445551                    0.038635   \n1                  0.122681                    0.012701   \n2                  0.699013                    0.019885   \n3                  0.201202                    0.057450   \n4                  0.284681                    0.014349   \n\n   novelty_artist_avg_year  mainstreaminess_avg_month  ...  \\\n0                 0.590222                   0.047020  ...   \n1                 0.272727                   0.012360  ...   \n2                 0.831252                   0.015331  ...   \n3                 0.295957                   0.105565  ...   \n4                 0.417029                   0.017248  ...   \n\n   user_groups_mainstreaminess_avg_6months_low  \\\n0                                            0   \n1                                            1   \n2                                            0   \n3                                            1   \n4                                            0   \n\n   user_groups_mainstreaminess_avg_6months_medium  \\\n0                                               1   \n1                                               0   \n2                                               0   \n3                                               0   \n4                                               1   \n\n   user_groups_mainstreaminess_avg_year  \\\n0                                   low   \n1                                   low   \n2                                   low   \n3                                medium   \n4                                   low   \n\n   user_groups_mainstreaminess_avg_year_high  \\\n0                                          0   \n1                                          0   \n2                                          0   \n3                                          0   \n4                                          0   \n\n   user_groups_mainstreaminess_avg_year_low  \\\n0                                         1   \n1                                         1   \n2                                         1   \n3                                         0   \n4                                         1   \n\n   user_groups_mainstreaminess_avg_year_medium  \\\n0                                            0   \n1                                            0   \n2                                            0   \n3                                            1   \n4                                            0   \n\n   user_groups_mainstreaminess_global  \\\n0                              medium   \n1                                 low   \n2                              medium   \n3                                high   \n4                                 low   \n\n   user_groups_mainstreaminess_global_high  \\\n0                                        0   \n1                                        0   \n2                                        0   \n3                                        1   \n4                                        0   \n\n   user_groups_mainstreaminess_global_low  \\\n0                                       0   \n1                                       1   \n2                                       0   \n3                                       0   \n4                                       1   \n\n   user_groups_mainstreaminess_global_medium  \n0                                          1  \n1                                          0  \n2                                          1  \n3                                          0  \n4                                          0  \n\n[5 rows x 359 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>country</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>age_group</th>\n      <th>playcount_lognorm</th>\n      <th>novelty_artist_avg_month</th>\n      <th>novelty_artist_avg_6months</th>\n      <th>novelty_artist_avg_year</th>\n      <th>mainstreaminess_avg_month</th>\n      <th>...</th>\n      <th>user_groups_mainstreaminess_avg_6months_low</th>\n      <th>user_groups_mainstreaminess_avg_6months_medium</th>\n      <th>user_groups_mainstreaminess_avg_year</th>\n      <th>user_groups_mainstreaminess_avg_year_high</th>\n      <th>user_groups_mainstreaminess_avg_year_low</th>\n      <th>user_groups_mainstreaminess_avg_year_medium</th>\n      <th>user_groups_mainstreaminess_global</th>\n      <th>user_groups_mainstreaminess_global_high</th>\n      <th>user_groups_mainstreaminess_global_low</th>\n      <th>user_groups_mainstreaminess_global_medium</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6782979</td>\n      <td>US</td>\n      <td>23</td>\n      <td>m</td>\n      <td>20-24</td>\n      <td>11.004597</td>\n      <td>0.445551</td>\n      <td>0.038635</td>\n      <td>0.590222</td>\n      <td>0.047020</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>low</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>medium</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3276804</td>\n      <td>NaN</td>\n      <td>22</td>\n      <td>n</td>\n      <td>20-24</td>\n      <td>11.512335</td>\n      <td>0.122681</td>\n      <td>0.012701</td>\n      <td>0.272727</td>\n      <td>0.012360</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>low</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>low</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13893641</td>\n      <td>RU</td>\n      <td>22</td>\n      <td>f</td>\n      <td>20-24</td>\n      <td>11.522579</td>\n      <td>0.699013</td>\n      <td>0.019885</td>\n      <td>0.831252</td>\n      <td>0.015331</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>low</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>medium</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13959183</td>\n      <td>CO</td>\n      <td>42</td>\n      <td>m</td>\n      <td>40-44</td>\n      <td>10.799739</td>\n      <td>0.201202</td>\n      <td>0.057450</td>\n      <td>0.295957</td>\n      <td>0.105565</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>medium</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>high</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26542097</td>\n      <td>DE</td>\n      <td>17</td>\n      <td>m</td>\n      <td>15-19</td>\n      <td>9.011646</td>\n      <td>0.284681</td>\n      <td>0.014349</td>\n      <td>0.417029</td>\n      <td>0.017248</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>low</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>low</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 359 columns</p>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df_without_missing_values.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}